{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2446924a7638f9fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T17:17:27.242489Z",
     "start_time": "2024-11-18T17:17:27.167029Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import scipy.sparse as sps\n",
    "from eals import ElementwiseAlternatingLeastSquares, load_model\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T17:17:28.724201Z",
     "start_time": "2024-11-18T17:17:27.902958Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "users = pd.read_csv('users.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n",
    "movies = pd.read_csv('movies.csv', sep='\\t', encoding='latin-1', usecols=['movie_id', 'title', 'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8669c5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0        1      1193       5  978300760\n",
       "1        1       661       3  978302109\n",
       "2        1       914       3  978301968\n",
       "3        1      3408       4  978300275\n",
       "4        1      2355       5  978824291"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b94851556846f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T16:40:36.970134Z",
     "start_time": "2024-11-18T16:40:36.229216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ratings.pivot(index = 'user_id', columns ='movie_id', values = 'rating').fillna(0)\n",
    "num_users, num_movies = df.shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61ca5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sparse = sps.csr_matrix(df.values, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "385a32a3b1ec6e8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T17:28:16.478103Z",
     "start_time": "2024-11-18T17:28:16.419514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['movie_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5409b58f9367f9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-18T17:22:46.582027Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 3706) (6040, 3706)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(ratings, test_size=0.1, random_state=42)\n",
    "\n",
    "# Get the unique user IDs and movie IDs\n",
    "unique_user_ids = ratings['user_id'].unique()\n",
    "unique_movie_ids = ratings['movie_id'].unique()\n",
    "\n",
    "# Create a mapping from the actual user and movie IDs to new continuous indices\n",
    "user_id_mapping = {user_id: idx for idx, user_id in enumerate(unique_user_ids)}\n",
    "movie_id_mapping = {movie_id: idx for idx, movie_id in enumerate(unique_movie_ids)}\n",
    "\n",
    "# Get the dimensions for the sparse matrices\n",
    "num_users = len(unique_user_ids)\n",
    "num_movies = len(unique_movie_ids)\n",
    "\n",
    "# Initialize the train and test matrices as empty numpy arrays\n",
    "train_data = np.zeros((num_users, num_movies), dtype=np.float32)\n",
    "test_data = np.zeros((num_users, num_movies), dtype=np.float32)\n",
    "\n",
    "# Populate the training data matrix\n",
    "for row in train_df.itertuples():\n",
    "    train_data[user_id_mapping[row.user_id], movie_id_mapping[row.movie_id]] = row.rating\n",
    "\n",
    "# Populate the testing data matrix\n",
    "for row in test_df.itertuples():\n",
    "    test_data[user_id_mapping[row.user_id], movie_id_mapping[row.movie_id]] = row.rating\n",
    "\n",
    "# Convert the numpy arrays into sparse matrices\n",
    "train_sparse = sps.csr_matrix(train_data)\n",
    "test_sparse = sps.csr_matrix(test_data)\n",
    "\n",
    "# Print the resulting shapes\n",
    "print(train_sparse.shape, test_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18f06981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6040, 3706), (6040, 3706))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sparse.shape, test_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32e1b04753b83aa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T17:34:32.724196Z",
     "start_time": "2024-11-18T17:34:17.019103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1 update_user loss=13.2122 (0.0390 sec)\n",
      "iter=1 update_item loss=5.9660 (0.1272 sec)\n",
      "iter=2 update_user loss=2.3586 (0.0850 sec)\n",
      "iter=2 update_item loss=1.6455 (0.0686 sec)\n",
      "iter=3 update_user loss=1.4333 (0.0570 sec)\n",
      "iter=3 update_item loss=1.3770 (0.0732 sec)\n",
      "iter=4 update_user loss=1.3202 (0.0878 sec)\n",
      "iter=4 update_item loss=1.2913 (0.0990 sec)\n",
      "iter=5 update_user loss=1.2590 (0.0761 sec)\n",
      "iter=5 update_item loss=1.2393 (0.0948 sec)\n",
      "iter=6 update_user loss=1.2166 (0.0747 sec)\n",
      "iter=6 update_item loss=1.2020 (0.1139 sec)\n",
      "iter=7 update_user loss=1.1847 (0.0873 sec)\n",
      "iter=7 update_item loss=1.1733 (0.0930 sec)\n",
      "iter=8 update_user loss=1.1594 (0.0701 sec)\n",
      "iter=8 update_item loss=1.1504 (0.1381 sec)\n",
      "iter=9 update_user loss=1.1390 (0.0920 sec)\n",
      "iter=9 update_item loss=1.1317 (0.0718 sec)\n",
      "iter=10 update_user loss=1.1221 (0.0540 sec)\n",
      "iter=10 update_item loss=1.1161 (0.0730 sec)\n",
      "iter=11 update_user loss=1.1078 (0.1002 sec)\n",
      "iter=11 update_item loss=1.1028 (0.1047 sec)\n",
      "iter=12 update_user loss=1.0956 (0.0530 sec)\n",
      "iter=12 update_item loss=1.0912 (0.0789 sec)\n",
      "iter=13 update_user loss=1.0849 (0.0718 sec)\n",
      "iter=13 update_item loss=1.0811 (0.0692 sec)\n",
      "iter=14 update_user loss=1.0755 (0.0723 sec)\n",
      "iter=14 update_item loss=1.0722 (0.0882 sec)\n",
      "iter=15 update_user loss=1.0671 (0.0689 sec)\n",
      "iter=15 update_item loss=1.0642 (0.0722 sec)\n",
      "iter=16 update_user loss=1.0595 (0.0763 sec)\n",
      "iter=16 update_item loss=1.0569 (0.1160 sec)\n",
      "iter=17 update_user loss=1.0527 (0.0820 sec)\n",
      "iter=17 update_item loss=1.0504 (0.0954 sec)\n",
      "iter=18 update_user loss=1.0465 (0.0739 sec)\n",
      "iter=18 update_item loss=1.0444 (0.0674 sec)\n",
      "iter=19 update_user loss=1.0408 (0.0530 sec)\n",
      "iter=19 update_item loss=1.0389 (0.0705 sec)\n",
      "iter=20 update_user loss=1.0356 (0.0532 sec)\n",
      "iter=20 update_item loss=1.0338 (0.0726 sec)\n"
     ]
    }
   ],
   "source": [
    "model = ElementwiseAlternatingLeastSquares(factors=20, num_iter=20)  # Default parameters\n",
    "model.fit(train_sparse, show_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d7ecf311dbc8f7c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T17:34:37.329132Z",
     "start_time": "2024-11-18T17:34:35.267640Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_ratings(model, df_sparse):\n",
    "    \"\"\"\n",
    "    Generate predictions only for the non-zero entries in the test set.\n",
    "    \"\"\"\n",
    "    user_factors = model.user_factors\n",
    "    item_factors = model.item_factors\n",
    "    \n",
    "    # Initialize an empty sparse matrix with the same shape as the test set\n",
    "    predictions_sparse = sps.lil_matrix(df_sparse.shape, dtype=np.float32)\n",
    "    \n",
    "    test_indices = df_sparse.nonzero()\n",
    "    \n",
    "    # Predict ratings only for the existing user-item pairs in the test set\n",
    "    for user, item in zip(test_indices[0], test_indices[1]):\n",
    "        predictions_sparse[user, item] = user_factors[user] @ item_factors[item]\n",
    "    \n",
    "    return predictions_sparse.tocsr()\n",
    "\n",
    "\n",
    "def calculate_rmse(df_sparse, predictions_sparse):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Squared Error between the actual and predicted ratings.\n",
    "    \"\"\"\n",
    "    # Ensure inputs are csr_matrix\n",
    "    df_sparse = sps.csr_matrix(df_sparse)\n",
    "    predictions_sparse = sps.csr_matrix(predictions_sparse)\n",
    "    \n",
    "    # Get the non-zero indices from the test set\n",
    "    test_indices = df_sparse.nonzero()\n",
    "    \n",
    "    # Extract actual and predicted ratings\n",
    "    actual_ratings = np.array(df_sparse[test_indices]).flatten()\n",
    "    predicted_ratings = np.array(predictions_sparse[test_indices]).flatten()\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c6f76e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set: 0.9804\n"
     ]
    }
   ],
   "source": [
    "predictions_sparse = predict_ratings(model, test_sparse)\n",
    "rmse = calculate_rmse(test_sparse, predictions_sparse)\n",
    "print(f\"RMSE on test set: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b8640",
   "metadata": {},
   "outputs": [],
   "source": [
    "class eAlsPredictor:\n",
    "    \"\"\"\n",
    "    A class to generate movie recommendations using the ElementwiseAlternatingLeastSquares model.\n",
    "\n",
    "    Parameters:\n",
    "    - model (ElementwiseAlternatingLeastSquares): A pre-trained model for generating user and item latent factors.\n",
    "    - train_sparse (sps.csr_matrix): A sparse matrix representing the training data (user-item ratings).\n",
    "    - movies (pd.DataFrame): A DataFrame containing information about movies (e.g., movie ID, title).\n",
    "    \"\"\"\n",
    "    def __init__(self, model: ElementwiseAlternatingLeastSquares, train_sparse: sps.csr_matrix, movies: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initializes the eAlsPredictor class with a trained model, training data, and movie data.\n",
    "        \n",
    "        Parameters:\n",
    "        - model (ElementwiseAlternatingLeastSquares): The trained ALS model used for making predictions.\n",
    "        - train_sparse (sps.csr_matrix): A sparse matrix of training data.\n",
    "        - movies (pd.DataFrame): DataFrame containing movie details (columns include 'movie_id', 'title').\n",
    "        \"\"\"\n",
    "        self._model = model\n",
    "        self._train_sparse = train_sparse\n",
    "        self._movies = movies\n",
    "\n",
    "\n",
    "    def _update_model(self, user_id: int, rated_items: dict[int, int]) -> None:\n",
    "        \"\"\"\n",
    "        Updates the model based on new ratings provided by the user.\n",
    "        \n",
    "        Parameters:\n",
    "        - user_id (int): The ID of the user.\n",
    "        - rated_items (dict[int, int]): A dictionary containing item IDs and corresponding ratings to update the model.\n",
    "        \"\"\"\n",
    "        for item_id, rating in rated_items.items():\n",
    "            self._model.update_model(user_id, item_id, rating)\n",
    "\n",
    "\n",
    "    def _get_recommend_items_ids(self, user_id: int, num_recommendations: int, num_random_items: int=0):\n",
    "        \"\"\"\n",
    "        Returns recommended item IDs for a given user.\n",
    "        \n",
    "        Parameters:\n",
    "        - user_id (int): The ID of the user for whom to generate recommendations.\n",
    "        - num_recommendations (int): The number of top recommendations to generate.\n",
    "        - num_random_items (int, optional): Number of random items to add to recommendations (default is 0).\n",
    "        \n",
    "        Returns:\n",
    "        - np.ndarray: Array of recommended item IDs.\n",
    "        \"\"\"\n",
    "        user_factors = self._model.user_factors\n",
    "        item_factors = self._model.item_factors\n",
    "\n",
    "        if user_id >= user_factors.shape[0]:\n",
    "            raise ValueError(f\"User ID {user_id} is out of range.\")\n",
    "        \n",
    "        # Compute scores for all items for the given user\n",
    "        user_vector = user_factors[user_id]\n",
    "        scores = user_vector @ item_factors.T\n",
    "\n",
    "        # Get the user's rated items from the training data\n",
    "        user_rated_items = self._train_sparse[user_id].nonzero()[1]\n",
    "\n",
    "        # Set scores for already rated items to a very low value to exclude them\n",
    "        scores[user_rated_items] = -np.inf\n",
    "\n",
    "        # Get the indices of the top N items with the highest scores\n",
    "        top_items_indices = np.argsort(scores)[-num_recommendations:][::-1]\n",
    "\n",
    "        # Add random items to the recommendations if num_random_items > 0\n",
    "        if num_random_items > 0:\n",
    "            random_items = np.random.choice(\n",
    "                np.setdiff1d(np.arange(item_factors.shape[0]), top_items_indices),\n",
    "                num_random_items,\n",
    "                replace=False\n",
    "            )\n",
    "            top_items_indices = np.concatenate([top_items_indices, random_items])\n",
    "        \n",
    "        return top_items_indices\n",
    "\n",
    "\n",
    "    def add_user(self, user_id: int, rated_items: dict[int, int]) -> None:\n",
    "        new_user_ratings = np.zeros(self._train_sparse.shape[1], dtype=np.float32)\n",
    "\n",
    "        # Update ratings for the rated items\n",
    "        for item_id, rating in rated_items.items():\n",
    "            new_user_ratings[item_id] = rating\n",
    "\n",
    "        # Convert to a csr_matrix and stack with the existing training matrix\n",
    "        new_user_sparse = sps.csr_matrix([new_user_ratings])\n",
    "        self._train_sparse = sps.vstack([self._train_sparse, new_user_sparse])\n",
    "\n",
    "        self._update_model(user_id, rated_items)\n",
    "\n",
    "\n",
    "    def add_rating_for_user(self, user_id: int, item_id: int, rating: int) -> None:\n",
    "        if user_id >= self._train_sparse.shape[0]:\n",
    "            raise ValueError(f\"User ID {user_id} is out of range. You may need to add the user first.\")\n",
    "\n",
    "        train_sparse_lil = self._train_sparse.tolil()\n",
    "        train_sparse_lil[user_id, item_id] = rating\n",
    "\n",
    "        self._train_sparse = train_sparse_lil.tocsr()\n",
    "        self._update_model(user_id, {item_id: rating})\n",
    "\n",
    "\n",
    "    def recommend_items(self, user_id: int, num_recommendations: int, num_random_items: int=0) -> pd.DataFrame:\n",
    "        if user_id >= self._model.user_factors.shape[0]:\n",
    "            raise ValueError(f\"User ID {user_id} is out of range. You may need to add the user first.\")\n",
    "        recommended_items = self._get_recommend_items_ids(user_id, num_recommendations, num_random_items)\n",
    "        \n",
    "        return self._movies[self._movies['movie_id'].isin(recommended_items)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea99e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = eAlsPredictor(model, df_sparse, movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d25a4d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1 update_model loss=1.0338 (0.0005 sec)\n",
      "iter=1 update_model loss=1.0338 (0.0010 sec)\n",
      "iter=1 update_model loss=1.0338 (0.0000 sec)\n",
      "iter=1 update_model loss=1.0338 (0.0010 sec)\n"
     ]
    }
   ],
   "source": [
    "pred.add_rating_for_user(1, 1, 5)\n",
    "pred.recommend_items(1, 5)\n",
    "pred.add_user(2, {1: 5, 2: 4, 3: 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "83d1b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current data in format of m-d-h to add to file name\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y_%H-%M\")\n",
    "\n",
    "# Save the model\n",
    "model_path = Path(\"models\") / f\"model_eALS_{dt_string}.joblib\"\n",
    "# convert model path to string\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca9c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
